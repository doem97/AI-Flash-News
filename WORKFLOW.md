# 🎯 AI 新闻生成工作流

> 这是项目的唯一核心配置文件。使用时只需告诉 Claude Code："按照 WORKFLOW.md 生成今天的新闻"

---

## 📰 新闻源列表

从以下网站抓取最近 24-48 小时的 AI 相关新闻：

| 新闻源                       | URL                                                             | 优先级 |
| ---------------------------- | --------------------------------------------------------------- | ------ |
| AI Breakfast                 | https://aibreakfast.beehiiv.com                                 | ⭐⭐⭐    |
| The Neuron Daily             | https://www.theneurondaily.com                                  | ⭐⭐⭐    |
| Ben's Bites                  | https://www.bensbites.com                                       | ⭐⭐⭐    |
| Artificial Intelligence News | https://www.artificialintelligence-news.com                     | ⭐⭐     |
| TechCrunch AI                | https://techcrunch.com/category/artificial-intelligence/        | ⭐⭐⭐    |
| The Verge AI                 | https://www.theverge.com/ai-artificial-intelligence             | ⭐⭐     |
| VentureBeat AI               | https://venturebeat.com/category/ai/                            | ⭐⭐     |
| MIT Technology Review        | https://www.technologyreview.com/topic/artificial-intelligence/ | ⭐⭐     |
| Hacker News                  | https://news.ycombinator.com                                    | ⭐⭐     |
| AIBase                       | https://www.aibase.com/zh/daily                                 | ⭐⭐⭐    |

**补充源（可选）：**
- Reddit r/artificial: https://www.reddit.com/r/artificial/

---

## 📊 信息提取要求

### 必须包含的量化信息

根据新闻类型，优先提取以下具体数据：

**产品发布类：**
- **定价**：具体价格、对比数据（如「比上代便宜 50%」、「$1/$5 每百万 tokens」）
- **性能**：benchmark 分数、速度提升倍数（如「比 M4 快 4 倍」、「SWE-bench 73.3%」）
- **规模**：参数量、上下文窗口、分辨率/时长（如「27B 参数」、「128K 上下文」）
- **可用性**：发布日期、支持平台、覆盖设备

**技术突破类：**
- **量化指标**：准确率、效率提升、参数规模（如「准确率达 95%」、「降低 40% 成本」）
- **对比基准**：超越了哪个模型/方法多少（如「超越 GPT-4 10 个百分点」）
- **应用场景**：具体解决什么问题、适用范围

**投融资类：**
- **金额**：具体数字（如「15 亿美元」、「A 轮 5000 万美元」）
- **估值**：融资后估值（如「估值达 100 亿美元」）
- **投资方**：lead investor、知名投资机构

**政策法规类：**
- **生效时间**：具体日期或时间范围
- **覆盖范围**：适用地区、行业、产品类型
- **处罚力度**：罚款金额、法律后果

**行业动态类：**
- **规模数据**：市场份额、用户数量、增长率（如「市占率达 35%」、「月活 1 亿」）
- **时间节点**：关键里程碑、预计时间表

### 写作原则

- ❌ **避免模糊表述**：「大幅提升」「显著改进」「快速增长」「巨大影响」
- ✅ **使用具体数据**：「提升 4 倍」「降低 66% 成本」「快 2.5 倍」「增长 150%」
- ❌ **避免空洞形容**：「革命性突破」「划时代意义」「颠覆性创新」
- ✅ **用事实说话**：「首个州级 AI 伴侣专项法规」「Flow 已创建 2.75 亿视频」

### 信息完整性要求

- 如果原文**缺少关键量化数据**，需在 content 中明确说明（如「具体参数未披露」）
- 如果新闻**处于早期阶段**，需注明（如「目前处于研究阶段」「尚未进入临床」）
- 如果信息**存在不确定性**，需标注（如「传闻」「未官方确认」）

---

## ⚖️ 新闻评估标准

### 评估维度

对每条新闻，从以下 5 个维度综合评估：

1. **影响范围**
   - 行业级：改变整个 AI 行业格局（如新法规、重大突破）
   - 赛道级：影响特定 AI 细分领域
   - 公司级：单个公司/产品动态

2. **创新程度**
   - 范式转变：全新的技术路径或方法论
   - 显著突破：现有框架内的重要进展
   - 渐进改进：常规性的优化和迭代
   - 常规发布：预期内的产品更新

3. **时效紧迫性**
   - 突发事件：今日发生的重大事件
   - 近期热点：最近 1-2 天的重要动态
   - 持续话题：正在发酵的长期议题

4. **实际应用价值**
   - 可落地性：技术是否已经可以实际应用
   - 用户影响：对终端用户的直接影响
   - 商业价值：对产业的实际推动作用

5. **话题性和争议度**
   - 引发讨论：是否可能引起广泛讨论
   - 存在争议：是否涉及伦理、安全等敏感话题
   - 意外性：是否出乎预期

### 重要性分级

**优先级排序原则：生态影响力 > 技术新颖性**

#### critical 判断标准（优先级从高到低）

1. **三大厂主流产品更新**
   - OpenAI/Google/Anthropic 的核心模型发布或重大更新
   - 理由：这些公司决定了下游生态，影响所有开发者和用户
   - 示例：Claude Haiku 4.5、Google Veo 3.1、GPT-5

2. **行业级政策法规**
   - 首例监管、重大法规变更、影响全行业的政策
   - 示例：加州首个 AI 伴侣监管法规、欧盟 AI 法案

3. **范式转变级技术突破**
   - 改变技术路径的创新（如 Transformer、LoRA）
   - 必须有**明确的量化证据**证明突破性

4. **主流科技巨头硬件发布**
   - Apple/NVIDIA/AMD 等的 AI 硬件重大更新
   - 理由：影响整个硬件生态和算力供应

**注意：**
- 每日 critical 级别控制在 **3-5 条**
- 如果没有足够的 critical 级别新闻，宁缺毋滥

#### high 判断标准

- **赛道级产品发布**：影响特定细分领域（如视频生成、代码助手）
- **重要研究突破**：已有验证但尚未大规模应用
- **高话题性事件**：引发广泛讨论（如 AI 伦理争议、法律纠纷）
- **大型投融资**：10 亿美元以上、或明星项目融资

#### medium 判断标准

- **常规产品更新**：预期内的版本迭代
- **区域性事件**：仅影响特定地区或市场
- **行业调研报告**：有参考价值但非突发事件
- **中等规模投融资**：1 亿美元以下

#### 降级情况（即使看起来重要也要降级）

- ❌ **早期研究**（未验证、不确定性高）→ 最高 high
  - 示例：Gemma 癌症研究（处于早期阶段，信息模糊）
- ❌ **信息模糊**（缺少关键细节、无法验证）→ 降一级
  - 示例：传闻、未官方确认的消息
- ❌ **区域性事件**（非全球影响）→ 最高 medium
  - 示例：单个国家/城市的投资计划

### 字数要求

根据重要性调整描述详细程度：

- **critical**：50-80 字
  - 包含：关键主体 + 核心内容 + 背景/原因 + 影响/意义

- **high**：35-50 字
  - 包含：关键主体 + 核心内容 + 简要影响

- **medium**：20-35 字
  - 包含：关键主体 + 核心事实

**原则：信息密度优先，不要为凑字数加废话**

### 写作规范

1. **标题（title）**：不超过 15 字，高度提炼
2. **内容（content）**：必须独立完整，包含完整主语和上下文
3. **中英文混排规则（重要！）**：中文和英文/数字交接处**必须有空格**
   - ✅ 正确：`OpenAI 发布`、`AI 简讯`、`GPT-4 模型`、`10 月 15 日`
   - ❌ 错误：`OpenAI发布`、`AI简讯`、`GPT-4模型`、`10月15日`
   - ✅ 正确：`Meta 推出 Llama 3.2 轻量版`
   - ❌ 错误：`Meta推出Llama 3.2轻量版`
4. **客观中立**：避免过度夸张
5. **中文流畅**：避免翻译腔

---

## 🗑️ 去重规则

### 历史数据检查

1. 读取最近 **7 天**的历史 JSON 文件（`data/YYYY-MM-DD.json`）
2. 提取所有已报道新闻的 `content` 和 `keywords`
3. 与新抓取的内容对比

### 去重判断

- **完全重复**（相似度 > 85%）→ 直接过滤
- **延续报道**（相似度 60-85%）→ 仅保留有实质新进展的
- **相似话题**（相似度 < 60%）→ 保留，但突出差异

---

## 📋 JSON 输出格式

```json
{
  "date": "2025-10-15",
  "date_formatted": "25/10/15",
  "title": "AI 闪电快讯",
  "news": [
    {
      "id": 1,
      "title": "新闻标题（≤15字）",
      "content": "新闻详细内容（20-80字，根据重要性调整）",
      "importance": "critical",
      "reasoning": "判断为 critical 的理由：影响范围（行业级）+ 创新程度（范式转变）",
      "source": "TechCrunch",
      "url": "https://...",
      "keywords": ["关键词1", "关键词2", "关键词3"],
      "category": "技术突破"
    }
  ],
  "metadata": {
    "generated_at": "2025-10-15T08:00:00Z",
    "total_news": 10,
    "sources_checked": ["AI Breakfast", "TechCrunch", "..."],
    "duplicates_removed": 5,
    "generation_time_seconds": 120.5
  }
}
```

### 字段说明

- **date**: ISO 格式日期（YYYY-MM-DD）
- **date_formatted**: 显示格式（YY/MM/DD）
- **title**: 固定为 "AI 闪电快讯"
- **news[]**: 新闻数组（8-12 条）
  - **id**: 排序序号（1-based）
  - **title**: 新闻标题（≤15 字）
  - **content**: 新闻描述（20-80 字）
  - **importance**: "critical" | "high" | "medium"
  - **reasoning**: AI 判断理由（供参考）
  - **source**: 新闻来源网站
  - **url**: 原文链接（必填）
  - **keywords**: 2-4 个关键词
  - **category**: 技术突破/产品发布/政策法规/投融资/行业动态/安全伦理
- **metadata**: 元数据
  - **generated_at**: 生成时间（ISO 8601）
  - **total_news**: 新闻总数
  - **sources_checked**: 已检查的新闻源列表
  - **duplicates_removed**: 去重数量
  - **generation_time_seconds**: 生成耗时

---

## ✅ 质量检查清单

生成后自我检查：

- [ ] 是否有重复/高度相似的新闻？
- [ ] critical 级别的新闻是否真的够重要？
- [ ] 字数是否符合 importance 级别？
- [ ] 每条新闻的信息密度是否足够？
- [ ] 是否所有新闻都来自最近 24-48 小时？
- [ ] JSON 格式是否有效？
- [ ] 是否提供了 reasoning 说明？
- [ ] keywords 是否准确？
- [ ] title 是否不超过 15 字？
- [ ] content 是否独立完整（包含主语）？
- [ ] **中英文之间是否都有空格？**（如 `AI 简讯`、`OpenAI 发布`）

---

## 📂 文件结构

生成的文件应保存在以下位置：

```
data/
├── raw/
│   └── 2025-10-15-raw.txt        # 原始抓取数据（可选）
└── 2025-10-15.json                # 前端使用的 JSON
```

前端会自动从根目录或 `data/` 目录加载最新的 JSON 文件。

---

## 📝 附录：内部执行流程

> 本章节供 Claude Code 参考，用户不需要关心具体步骤

当用户说："按照 WORKFLOW.md 生成今天（YYYY-MM-DD）的 AI 新闻简报"时，Claude Code 会自动执行以下步骤：

1. **抓取新闻源**
   - 使用 WebFetch 工具访问所有配置的新闻源
   - 提取最近 24-48 小时的 AI 相关新闻

2. **保存原始数据（可选）**
   - 将抓取的原始内容保存到 `data/raw/YYYY-MM-DD-raw.txt`
   - 用于后续追溯和调试

3. **读取历史数据去重**
   - 读取 `data/` 目录下最近 7 天的 JSON 文件
   - 提取已报道新闻的关键词和内容
   - 对比新抓取的内容，过滤重复新闻

4. **分析和筛选**
   - 根据评估标准（影响范围、创新程度等）评估每条新闻
   - 判断重要性等级（critical/high/medium）
   - 筛选出 8-12 条最值得关注的新闻

5. **撰写和生成**
   - 根据重要性级别撰写相应长度的描述（20-80 字）
   - 确保中英文混排规范（添加空格）
   - 生成符合格式的 `data/YYYY-MM-DD.json`

6. **质量检查**
   - 对照质量检查清单自我检查
   - 确保所有规范都已满足
